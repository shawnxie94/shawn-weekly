---
date: 2025-04-07
---
# 肖恩技术周刊（第 43 期）：电子榨菜
> **周刊内容**: 对一周内阅读的资讯或技术内容精品（个人向）进行总结，分类大致包含“业界资讯”、“技术博客”、“开源项目”和“学习资源”等。<br>
> **更新时间**: 周一<br>
> **历史收录**: [技术周刊合集](https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzkwODY0ODQzOQ==&action=getalbum&album_id=3492416248238096386#wechat_redirect) <br>
> **订阅方式**: 微信公众号“**肖恩聊技术**”，除周刊外还有更多原创技术博文，欢迎关注👏🏻~<br>
> <img src="https://cdn.jsdelivr.net/gh/Xiaoxie1994/images/images/20241103221454.png" alt="公众号二维码" width="300">

## 开篇图
![](https://cdn.jsdelivr.net/gh/Xiaoxie1994/images/images/202504062337766.png)

这哥们真的是直播鬼才，切片能看一下午。
## 业界资讯
### [抖音安全与信任中心](https://95152.douyin.com/)
![](https://cdn.jsdelivr.net/gh/Xiaoxie1994/images/images/202504062322669.png)

抖音建立安全与信任中心，推进算法和平台治理透明化。
## 技术博客
### [去哪儿高峰期资源保障之智能扩缩容](https://mp.weixin.qq.com/s/b9-PG9Uz2tBxCwgxcmTJyw)
![](https://cdn.jsdelivr.net/gh/Xiaoxie1994/images/images/202504062325887.png)

去哪儿网针对业务高峰期资源保障问题，开发了智能扩缩容方案，通过流量日历平台整合业务监控与运维数据，利用算法预测业务高峰时的资源需求，并自动执行扩缩容操作。该方案覆盖了考试、节假日和促销活动等多种业务高峰场景，通过九个阶段的业务流程实现从事件预判到复盘的全流程管理。

在业务流程方面，系统支持热点事件录入，根据事件类型和业务涨幅预估高峰期业务量，调用算法接口预测 CPU 核数，并结合安全阈值计算预估机器数。运维团队根据预估结果创建定时扩缩容任务，使用本地和云上资源执行操作。任务高峰期结束后，进入复盘阶段，分析预测准确率和覆盖率，以改进算法和流程。

算法部分采用神经网络模型，通过分析订单量、QPS、机器型号等影响 CPU 的因素进行训练，考察平均绝对百分比误差（MAPE）和相关性系数等指标。模型离线定时更新，学习高峰事件和近期数据，确保模型的时效性和鲁棒性。同时，系统设置了最大副本数和最小副本数的安全限制，保障机器数预测过低场景下的稳定性。

项目实施后，应用接入数量达到 150 个以上，占比酒店应用总核数 90% 以上，已完成多种重点高峰事件保障。应用预估平均覆盖度为 96%，准确率为 89%。单次事件高峰期节约人工运维效率 3pd/次，年化节约 270pd，相比人工预测资源节省约 20%。

未来，去哪儿网计划进一步拓展智能扩缩容的应用场景，包括实体机/KVM 场景和存储层资源，并提升容量扩容的安全性检测。同时，将继续优化算法，借助 AI 提升业务量预估准确性和业务指标与应用 CPU 的关联性，逐步覆盖公司各业务线，实现全司资源调度智能化。
### [LLM应用落地实施手册](https://mp.weixin.qq.com/s/t-uYwd9NOxJIAIMAYWEqhg)
 ![](https://cdn.jsdelivr.net/gh/Xiaoxie1994/images/images/202504062325365.png)

本文是一份关于大型语言模型（LLM）应用落地实施的手册，作者林然结合自身开发经验，详细介绍了如何系统性地实施基于LLM的应用。文章首先介绍了LLM应用的常见场景，如文本分类、信息抽取、文本生成、对话系统等，并将其分为会话型和任务型两大类。会话型应用以用户输入为核心，输入复杂且涉及对话上下文；任务型应用则以系统数据为输入，输入较为固定，通常采用批处理方式。

在复杂度评估方面，作者将LLM应用划分为L1到L4四个级别，从简单的单轮调用到复杂的自主规划Agent。用户体验风险也是关键考量因素，错误影响和任务失败概率直接影响应用的成功与否。

文章进一步介绍了L3级LLM应用的构建方式，包括架构设计、知识工程、模型优化和迭代优化。架构设计强调任务拆解和检索增强，知识工程涉及构建多种知识库，模型优化则包括Prompt优化和模型微调。迭代优化则通过建立评估指标和记录实验结果来不断改进系统。

最后，文章通过一个具体的Text-to-SQL应用案例，展示了从需求分析、用户体验风险评估、架构设计、知识工程到开发落地及优化的全过程。该项目通过优化架构和知识工程，将Text-to-SQL的准确率从10%提升至90%以上，充分体现了LLM应用落地实施的有效性和潜力。
## 开源项目 
### [local-deep-researcher：本地深度研究员](https://github.com/langchain-ai/local-deep-researcher)
![](https://cdn.jsdelivr.net/gh/Xiaoxie1994/images/images/202504062242531.png)

利用本地运行的语言模型（LLM），如Ollama或LMStudio提供的模型，帮助用户进行深度网络研究，并生成带有引用的研究报告。
### [RD-Agent：AI驱动研发自动化](https://github.com/microsoft/RD-Agent)
![](https://cdn.jsdelivr.net/gh/Xiaoxie1994/images/images/202504062328998.png)

RD-Agent 是一个旨在实现AI驱动研发自动化的项目，目前处于预览阶段，其核心目标是简化模型和数据开发流程，为工业研发创造价值。
### [neovim：Vim 激进重构版本](https://github.com/neovim/neovim)
![](https://cdn.jsdelivr.net/gh/Xiaoxie1994/images/images/202504062332547.png)

Vim 激进重构版本，专注于可扩展性和可用性。
## 学习资源
### [Awesome-LLM-Post-training：大模型后训练资源](https://github.com/mbzuai-oryx/Awesome-LLM-Post-training)
![](https://cdn.jsdelivr.net/gh/Xiaoxie1994/images/images/202504062338756.png)

大型语言模型（LLMs）后训练方法的深入研究，提供了一个全面的资源库，涵盖了与LLMs后训练方法相关的最具影响力的论文、代码实现、基准测试和资源。
### [ai-engineering-hub：人工智能工程资源](https://github.com/patchy631/ai-engineering-hub)
![](https://cdn.jsdelivr.net/gh/Xiaoxie1994/images/images/202504062338376.png)

提供AI工程领域深度教程、代码示例和资源，帮助用户学习和实践。
### [油猴开发指南](https://learn.scriptcat.org/)
![](https://cdn.jsdelivr.net/gh/Xiaoxie1994/images/images/202504062333401.png)

更适合国人体质的油猴教程。
## 随便看看
### [Vibe Coding彻底火了，到底什么是“氛围编程”？它如何改变未来的软件开发？](https://www.mittrchina.com/news/detail/14590)
![](https://cdn.jsdelivr.net/gh/Xiaoxie1994/images/images/202504062339060.png)

“氛围编程”（Vibe Coding）是由 OpenAI 联合创始人 Andrej Karpathy 提出的一种新型编程方式。它强调开发者无需深入理解代码细节，而是通过 AI 辅助快速实现功能。Karpathy 用此方法在一小时内用 Swift 完成了一个 iOS 应用的开发，展示了其高效性。该方法的核心是让开发者专注于功能效果，而非代码本身，从而大大降低了编程的门槛，使更多人能够参与到软件开发中来。

“氛围编程”正在改变软件开发行业，它推动了编程的民主化，让小团队能够快速开发出产品并创造高收入业务。它还可能改变软件的风格和设计，带来全新的交互模式，并重新定义软件开发的价值链，使软件的价值更依赖于创造力而非单纯的代码能力。

然而，“氛围编程”也存在一些局限性。由于开发者可能不完全理解代码，这可能导致代码质量和可维护性问题，甚至可能引入安全漏洞。此外，该方法目前更适合低风险的个人项目和概念验证工作。尽管如此，“氛围编程”仍为软件开发带来了新的可能性和机遇。