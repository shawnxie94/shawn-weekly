import{_ as e,c as n,b as i,o as t}from"./app-BRqSOp5B.js";const r={};function c(p,a){return t(),n("div",null,[...a[0]||(a[0]=[i('<h1 id="肖恩技术周刊-第-83-期-金句达人" tabindex="-1"><a class="header-anchor" href="#肖恩技术周刊-第-83-期-金句达人"><span>肖恩技术周刊（第 83 期）：金句达人</span></a></h1><blockquote><p>对周内阅读的技术内容精品（个人向）进行总结。觉得不错可点击上方订阅，第一时间获取更新通知。</p></blockquote><figure><img src="https://images.weserv.nl/?url=cdn.jsdelivr.net%2Fgh%2Fshawnxie94%2Fimages%2Fimages%2F20260215221619389.png&amp;output=webp&amp;q=78" alt="" tabindex="0" data-origin-src="https://cdn.jsdelivr.net/gh/shawnxie94/images/images/20260215221619389.png" referrerpolicy="no-referrer" decoding="async" loading="lazy"><figcaption></figcaption></figure><p>蛇年最后一周，时间主要用在年终总结撰写和 <strong>Lumina</strong> 工具打磨上了，周刊开题就稍微水水吧，哈哈。</p><p><a href="https://shawnxie.top/blogs/talk/2025-end.html" target="_blank" rel="noopener noreferrer">蛇年（2025）总结：决定</a>，回顾了一年的心路历程和创作记录。没啥高光时刻，但至少保持在正道上，心里踏实不少。</p><p>Lumina 发布了第一个正式版，核心功能基本成型，虽然离成熟产品还有不少距离，但个人开发比较忌讳过度打磨产品，尽快推向社区才能得到更多的反馈。在打磨中发现 AI 总结/找金句真是一把好手，能抓住文章的核心观点高度凝练，用词也很恰当，列举一些：</p><ul><li>当人开始看不懂自己仓库里的代码，不是生产力起飞，而是工程正在失控。</li><li>你以为自己在“高效学习”，其实是在用生产力的幻觉，填补不敢面对真实生活的恐惧。</li><li>成瘾的本质不是你做了什么，而是你用它来逃避什么；它承诺解放，却带来囚禁。</li><li>最好的工程师不是更快，而是更狠：把注意力留给对的事，让错的事理直气壮地烂在待办里。</li><li>历史正在加速发生，洪流中容易五色迷目；越是喧嚣的时代，越需要把“连点成线”的能力握在手里。</li><li>人的意义不在于工作；而在这趟旅程里，“大模型不能替你活过”。</li><li>速度若不伴随理解，只是在用更快的方式积累失明。</li><li>AI让“多做一点”变得轻而易举，却让“及时停下”变得越来越难。</li><li>生产力的短期暴涨，往往掩盖了工作量的静默膨胀与认知负债的累积。</li><li>把键盘交给 AI、把审查交给运气，这不是工程，只是“希望它能跑”。</li><li>当任何人都能几分钟生成上千行代码，“我们不需要这个”将比“我们做得到”更值钱。</li><li>当你持续把模型按在自己的失误上摩擦，它会为了逃出循环而“梦”出一个可用的解。</li><li>真正厉害的工程师，不是沉迷技术答案，而是倒推用户问题，让解法从理解里自然长出来。</li><li>做对一千件小事，比做对三件大事更重要。</li><li>每个时代都被一种“奇迹材料”重塑；掌握它的人，定义这个时代的边界。</li><li>你以为在争论技术，其实是在争夺身份；语言之争的胜负，往往早在自我认同里就已写好结局。</li></ul><p>最后祝大家除夕快乐，马年不做牛马，做黑马！</p><p>PS：下周停更一周。</p><h2 id="业界资讯" tabindex="-1"><a class="header-anchor" href="#业界资讯"><span>业界资讯</span></a></h2><h3 id="seedance-2-0-正式发布-统一多模态架构-5秒音画一体-直击工业级创作" tabindex="-1"><a class="header-anchor" href="#seedance-2-0-正式发布-统一多模态架构-5秒音画一体-直击工业级创作"><span><a href="https://www.aibase.com/zh/news/25492" target="_blank" rel="noopener noreferrer">Seedance 2.0 正式发布：统一多模态架构 5秒音画一体，直击工业级创作</a></span></a></h3><figure><img src="https://lumina.shawnxie.top/backend/media/2026/02/f504030f15454a4abc9053badd6dc993.png" alt="" tabindex="0" decoding="async" loading="lazy"><figcaption></figcaption></figure><p>字节Seed团队于2026年2月12日发布Seedance2.0，采用统一音视频多模态联合生成架构，支持15秒多镜头立体声输出与文图音视频混合参考（最多9图）并可定向编辑续拍，已上线即梦AI和豆包，提升复杂运动与多人交互可用率、降低影视广告电商制作成本，推动AI视频迈入工业化但一致性与细节仍待优化。</p><h3 id="豆包大模型-2-0-正式上线-推理成本降一个数量级-api-同步开放" tabindex="-1"><a class="header-anchor" href="#豆包大模型-2-0-正式上线-推理成本降一个数量级-api-同步开放"><span><a href="https://www.aibase.com/zh/news/25537" target="_blank" rel="noopener noreferrer">豆包大模型 2.0 正式上线 推理成本降一个数量级 API 同步开放</a></span></a></h3><figure><img src="https://lumina.shawnxie.top/backend/media/2026/02/e436400805534eceacad68f6c4cd9405.png" alt="" tabindex="0" decoding="async" loading="lazy"><figcaption></figcaption></figure><p>火山引擎发布豆包大模型2.0系列并上线企业与开发者API，围绕生产环境优化推理、多模态与复杂指令执行，推理成本较顶尖模型降约一数量级且日均Tokens增长超500倍，提供Pro/Lite/Mini/Code四款以覆盖深推理、性价比、低延迟与编程场景，视觉与视频理解及多项基准领先并强化Agent与工具调用能力，同时更新Coding Plan以降低开发者用量成本、提升落地效率。</p><h3 id="gemini-3-深度思考-推动科学、研究与工程发展" tabindex="-1"><a class="header-anchor" href="#gemini-3-深度思考-推动科学、研究与工程发展"><span><a href="https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-deep-think/" target="_blank" rel="noopener noreferrer">Gemini 3 深度思考：推动科学、研究与工程发展</a></span></a></h3><figure><img src="https://lumina.shawnxie.top/backend/media/2026/02/ad2593521aaf4310b7155789e4cb0430.png" alt="" tabindex="0" decoding="async" loading="lazy"><figcaption></figcaption></figure><p>谷歌升级Gemini 3 Deep Think推理模式，Ultra订阅者即日起在Gemini应用可用，科研人员与企业可申请通过Gemini API早期接入；新版本在数学、编程、物理化学等基准成绩提升，并支持论文审查、材料工艺与部件设计及草图生成3D打印文件，旨在加速科研与工程落地。</p><h3 id="国产-ai-大模型竞争升级-智谱-glm-5-与-minimax-2-5-联袂发布" tabindex="-1"><a class="header-anchor" href="#国产-ai-大模型竞争升级-智谱-glm-5-与-minimax-2-5-联袂发布"><span><a href="https://www.aibase.com/zh/news/25476" target="_blank" rel="noopener noreferrer">国产 AI 大模型竞争升级：智谱 GLM-5 与 MiniMax 2.5 联袂发布</a></span></a></h3><figure><img src="http://lumina.shawnxie.top/backend/media/2026/02/357707cb9745409a9870d5a81f2d6be4.png" alt="" tabindex="0" decoding="async" loading="lazy"><figcaption></figcaption></figure><p>春节期间国产大模型加速迭代，DeepSeek后智谱AI上线GLM-5与MiniMax2.5，GLM-5在z.ai发布，主攻对话、编程与智能体，采用稀疏注意力与多Token预测路线，参数规模与上下文能力显著提升，MiniMax2.5距2.2仅一月即更新，两者引发开发者实测，行业竞争转向更高参数与效率比拼。</p><h3 id="推出-gpt-5-3-codex-spark" tabindex="-1"><a class="header-anchor" href="#推出-gpt-5-3-codex-spark"><span><a href="https://openai.com/index/introducing-gpt-5-3-codex-spark/" target="_blank" rel="noopener noreferrer">推出 GPT-5.3-Codex-Spark</a></span></a></h3><figure><img src="https://lumina.shawnxie.top/backend/media/2026/02/0c26b7894a3e44cb8390a6de287b6023.png" alt="" tabindex="0" decoding="async" loading="lazy"><figcaption></figcaption></figure><p>OpenAI发布研究预览GPT‑5.3‑Codex‑Spark，基于Cerebras低延迟硬件实现实时编程协作，128k上下文文本模式，支持超千token/秒并默认轻量修改；同时改造端到端链路使首token更快、往返与逐token开销显著下降，将先向ChatGPT Pro与少量API伙伴开放并扩容，推动Codex形成实时迭代与长任务并行的双模式。</p><h2 id="佳文共赏" tabindex="-1"><a class="header-anchor" href="#佳文共赏"><span>佳文共赏</span></a></h2><h3 id="在谷歌-14-年的-14-个额外经验教训" tabindex="-1"><a class="header-anchor" href="#在谷歌-14-年的-14-个额外经验教训"><span><a href="https://addyosmani.com/blog/14-more-lessons/" target="_blank" rel="noopener noreferrer">在谷歌 14 年的 14 个额外经验教训</a></span></a></h3><figure><img src="https://lumina.shawnxie.top/backend/media/2026/02/87ec7e10cacc490dae5b69046497393e.jpg" alt="" tabindex="0" decoding="async" loading="lazy"><figcaption></figcaption></figure><p>作者基于谷歌经历总结团队工程要诀：只做高价值问题，会议先明确决策诉求，用“周二某人做X”替代空泛意向，权责清晰以加速决策，可靠性与可观测性纳入完成标准，跨团队靠清晰接口与带方案升级，反英雄并警惕扩编带来的协作边，迁移要有人负责收尾与退役期限，AI时代品味与信任决定交付速度。</p><h3 id="人工智能并不减少工作量——它加剧了工作量" tabindex="-1"><a class="header-anchor" href="#人工智能并不减少工作量——它加剧了工作量"><span><a href="https://hbr.org/2026/02/ai-doesnt-reduce-work-it-intensifies-it" target="_blank" rel="noopener noreferrer">人工智能并不减少工作量——它加剧了工作量</a></span></a></h3><figure><img src="http://lumina.shawnxie.top/backend/media/2026/02/7933e5cfe54546959c7820efb04be492.jpg" alt="" tabindex="0" decoding="async" loading="lazy"><figcaption></figcaption></figure><p>研究跟踪一家约200人科技公司8个月发现，生成式AI未减负而让员工自发提速、扩任务、延长工作时段并更频繁多线程，短期产出上升却累积隐性工作膨胀与认知负荷，最终易致疲劳倦怠、决策变差与质量下滑，组织需建立AI使用规范以限制扩张并保留停顿。</p><h3 id="生成式和智能体-ai-如何将关注点从技术债务转向认知债务" tabindex="-1"><a class="header-anchor" href="#生成式和智能体-ai-如何将关注点从技术债务转向认知债务"><span><a href="https://margaretstorey.com/blog/2026/02/09/cognitive-debt/" target="_blank" rel="noopener noreferrer">生成式和智能体 AI 如何将关注点从技术债务转向认知债务</a></span></a></h3><figure><img src="https://lumina.shawnxie.top/backend/media/2026/02/b4187653a3eb482ea3e8db0d7e1ec344.webp" alt="" tabindex="0" decoding="async" loading="lazy"><figcaption></figcaption></figure><p>AI加速开发使“认知债务”累积在开发者心智而非代码，团队因丢失系统共同理解与决策依据而难以安全改动甚至停滞；应放慢节奏，通过结对、重构、TDD、强制至少一人理解AI改动并记录为何变更来重建共享理论，同时建立预警检测与量化研究以防认知债务致瘫痪。</p><h3 id="成瘾者-色情、赌博与vibe-coding" tabindex="-1"><a class="header-anchor" href="#成瘾者-色情、赌博与vibe-coding"><span><a href="https://x.com/wquguru/article/2022173077329871138" target="_blank" rel="noopener noreferrer">成瘾者：色情、赌博与Vibe Coding</a></span></a></h3><figure><img src="https://lumina.shawnxie.top/backend/media/2026/02/823d067aa312454686741451af34f4d8.webp" alt="" tabindex="0" decoding="async" loading="lazy"><figcaption></figcaption></figure><p>提出Vibe Coding与色情、赌博共享间歇性强化的成瘾机制，人在饥饿愤怒孤独疲惫等触发下不断追逐不确定奖励与虚假生产力，结果社交与健康被牺牲且深度思考和技能退化，解决路径是识别触发与自我辩护的“子人格”、在冲动前暂停并重建目标和身份，用真实联结与长期成长替代即时快感。</p><h3 id="最后的瓶颈" tabindex="-1"><a class="header-anchor" href="#最后的瓶颈"><span><a href="https://lucumr.pocoo.org/2026/2/13/the-final-bottleneck/" target="_blank" rel="noopener noreferrer">最后的瓶颈</a></span></a></h3><figure><img src="https://lumina.shawnxie.top/backend/media/2026/02/bd1461b683e142c2826c29ef9a2f865d.png" alt="" tabindex="0" decoding="async" loading="lazy"><figcaption></figcaption></figure><p>AI加速写码引发PR激增与审查吞吐不足，开源和“AI优先”团队出现无法分诊、过期难合并与贡献者失去动力的积压；要维持系统只能限流与更多机器自检，但由于责任不可由机器承担，人必须理解并签署交付，人仍是最终瓶颈。</p><h3 id="单披萨工程团队开始兴起" tabindex="-1"><a class="header-anchor" href="#单披萨工程团队开始兴起"><span><a href="https://www.jampa.dev/p/the-rise-of-one-pizza-engineering" target="_blank" rel="noopener noreferrer">单披萨工程团队开始兴起</a></span></a></h3><figure><img src="https://lumina.shawnxie.top/backend/media/2026/02/7c15b0f5aef44741a91e55b22ccd743d.jpg" alt="" tabindex="0" decoding="async" loading="lazy"><figcaption></figcaption></figure><p>AI让写码不再是瓶颈，产出开始受制于PM规格与设计线框交付速度，组织因此引入兼顾产品与设计职责的产品工程师并强化前后端专家把关以防AI劣化代码质量，项目更适合2-3名工程师小组推进且管理者更常参与编码，两披萨团队规模规则随之被弱化。</p><h3 id="玩-ai-视频-角色老是换脸-我花了3个月才搞明白问题出在哪儿-上篇" tabindex="-1"><a class="header-anchor" href="#玩-ai-视频-角色老是换脸-我花了3个月才搞明白问题出在哪儿-上篇"><span><a href="https://x.com/ponyodong/article/2022220396515442988" target="_blank" rel="noopener noreferrer">玩 AI 视频，角色老是换脸？我花了3个月才搞明白问题出在哪儿(上篇）</a></span></a></h3><figure><img src="https://lumina.shawnxie.top/backend/media/2026/02/09c416a07d704b95885f2899bfad669e.png" alt="" tabindex="0" decoding="async" loading="lazy"><figcaption></figcaption></figure><p>作者拆解长视频换脸根因：只上传参考图仅锁定外貌，需用六棱镜6D补全运镜、物理反馈、时间线、剪辑节奏与光影氛围，并先建角色资产库再写6D笔记转自然语言流生成，结论是可显著提升可用率、让角色跨镜头保持一致并减少积分浪费。</p><h2 id="技术博客" tabindex="-1"><a class="header-anchor" href="#技术博客"><span>技术博客</span></a></h2><h3 id="如何基于-obsidian-和-claude-打造-ai-时代超级大脑" tabindex="-1"><a class="header-anchor" href="#如何基于-obsidian-和-claude-打造-ai-时代超级大脑"><span><a href="https://x.com/yanhua1010/article/2020342019575673223" target="_blank" rel="noopener noreferrer">如何基于 Obsidian 和 Claude 打造 AI 时代超级大脑？</a></span></a></h3><figure><img src="https://lumina.shawnxie.top/backend/media/2026/02/6bc0f80b22f74c7aa45a90cc46c621da.png" alt="" tabindex="0" decoding="async" loading="lazy"><figcaption></figcaption></figure><p>作者将Obsidian接入Claude（Claudian+终端），用CLAUDE.md固化身份与协作规则，并以16个Skill把采集、写稿、配图、跨平台发布模块化自动化，使播客素材到带图成文发布压缩至约30分钟，结论是“超级大脑”在于把个人工作方式文字化并让AI按此执行。</p><h3 id="_2026-年了-就用-postgres-吧" tabindex="-1"><a class="header-anchor" href="#_2026-年了-就用-postgres-吧"><span><a href="https://www.tigerdata.com/blog/its-2026-just-use-postgres" target="_blank" rel="noopener noreferrer">2026 年了，就用 Postgres 吧</a></span></a></h3><figure><img src="https://lumina.shawnxie.top/backend/media/2026/02/378b17470ff842eebe3a52666b9887c1.png" alt="" tabindex="0" decoding="async" loading="lazy"><figcaption></figcaption></figure><p>作者主张在AI时代用Postgres统一搜索、向量、时序、队列等能力，通过扩展提供与专用数据库相同或更优算法，减少多库导致的运维学习成本、数据同步漂移与SLA叠加故障，结论是99%团队应先用Postgres，仅在极端规模再引入专用库。</p><h3 id="openai-智能体工程指南-10-条实战技巧和-3-种构建模式" tabindex="-1"><a class="header-anchor" href="#openai-智能体工程指南-10-条实战技巧和-3-种构建模式"><span><a href="https://baoyu.io/blog/2026-02-12/skills-shell-tips" target="_blank" rel="noopener noreferrer">OpenAI 智能体工程指南：10 条实战技巧和 3 种构建模式</a></span></a></h3><figure><img src="https://lumina.shawnxie.top/backend/media/2026/02/e601f113e0554115857b40e4aeccf487.webp" alt="" tabindex="0" decoding="async" loading="lazy"><figcaption></figcaption></figure><p>OpenAI 发布智能体工程手册，提出用Skills按需加载流程、Shell提供执行环境、Compaction自动压缩上下文，并用清晰技能描述与负面示例提升多技能路由可靠性，实测可支撑百万级token与多次工具调用的长期运行且促成跨厂商技能标准化。</p><h3 id="agent-工程师-是怎么用-ai-写代码的" tabindex="-1"><a class="header-anchor" href="#agent-工程师-是怎么用-ai-写代码的"><span><a href="https://x.com/yan5xu/article/2021162107170095186" target="_blank" rel="noopener noreferrer"> Agent 工程师，是怎么用 AI 写代码的</a></span></a></h3><figure><img src="http://lumina.shawnxie.top/backend/media/2026/02/5f59b550a04a4b239f552496894c149e.png" alt="" tabindex="0" decoding="async" loading="lazy"><figcaption></figcaption></figure><p>Agent工程师用GPT-4到多种coding agent一年多将生产开发交给AI，发现瓶颈是上下文丢失而非模型能力，于是用HANDOFF结构化交接替代压缩、用Sub-Agent分工与文件传递扩容上下文、用git worktree隔离并发，并给agent全局多仓视图与测试日志CLI自验证能力，协作方式转为Issue驱动开发与PR审查，最终沉淀并开源Code Relay协议复用该工作流。</p><h3 id="uber的限流系统" tabindex="-1"><a class="header-anchor" href="#uber的限流系统"><span><a href="https://www.uber.com/en-HK/blog/ubers-rate-limiting-system/" target="_blank" rel="noopener noreferrer">Uber的限流系统</a></span></a></h3><figure><img src="https://lumina.shawnxie.top/backend/media/2026/02/4b43ff3e3c1b4196a77e71229f60d458.jpg" alt="" tabindex="0" decoding="async" loading="lazy"><figcaption></figcaption></figure><p>Uber在服务网格内推全局限流GRL，采用分层聚合由控制平面下发丢弃比例的概率限流取代Redis计数与令牌桶，并用RLC基于历史流量自动计算并更新配额，能有效降低端到端延迟与运维成本、释放存储资源，在流量峰值与攻击下提升平台稳定性与公平性。</p><h3 id="您的公司是一个文件系统" tabindex="-1"><a class="header-anchor" href="#您的公司是一个文件系统"><span><a href="https://x.com/mernit/article/2021324284875153544" target="_blank" rel="noopener noreferrer">您的公司是一个文件系统</a></span></a></h3><figure><img src="http://lumina.shawnxie.top/backend/media/2026/02/74163cc9f26441ddbc92d157a9f8a7a6.jpg" alt="" tabindex="0" decoding="async" loading="lazy"><figcaption></figcaption></figure><p>Openclaw将对话与数据映射为本机文件，调用Claude读写文件完成任务；若把公司也建模为统一文件系统，案件、计费、权限等以目录与权限表示，打通分散系统数据，AI代理即可凭共享命名空间获取上下文并做决策，文件系统将成代理的事实源。</p><h2 id="开源项目" tabindex="-1"><a class="header-anchor" href="#开源项目"><span>开源项目</span></a></h2><h3 id="kaku-专为ai编程设计的终端" tabindex="-1"><a class="header-anchor" href="#kaku-专为ai编程设计的终端"><span><a href="https://github.com/tw93/Kaku" target="_blank" rel="noopener noreferrer">Kaku：专为AI编程设计的终端</a></span></a></h3><figure><img src="https://lumina.shawnxie.top/backend/media/2026/02/ddbf43713b7c451cbb3d0ec366ab0796.webp" alt="" tabindex="0" decoding="async" loading="lazy"><figcaption></figcaption></figure><p>Kaku是基于WezTerm深度定制的AI编程终端，提供默认美观界面、面向AI工作流优化、精简功能提升性能、macOS原生体验与GPU加速渲染，并保留Lua脚本配置。</p><h3 id="likec4-开源的架构建模工具" tabindex="-1"><a class="header-anchor" href="#likec4-开源的架构建模工具"><span><a href="https://github.com/likec4/likec4" target="_blank" rel="noopener noreferrer">likec4：开源的架构建模工具</a></span></a></h3><figure><img src="https://lumina.shawnxie.top/backend/media/2026/02/cb92a733b519449ba74a1fcfb5482a76.webp" alt="" tabindex="0" decoding="async" loading="lazy"><figcaption></figcaption></figure><p>LikeC4是开源架构建模工具，采用DSL设计并可视化维护基于C4的架构，写代码时图表实时更新并与Git版本控制集成，支持通过MCP或API向AI代理暴露架构信息，还可将交互式图表以React或Web组件嵌入文档、网站或应用。</p><h3 id="lumina-一站式信息管理工作台" tabindex="-1"><a class="header-anchor" href="#lumina-一站式信息管理工作台"><span><a href="https://github.com/shawnxie94/lumina" target="_blank" rel="noopener noreferrer">Lumina：一站式信息管理工作台</a></span></a></h3><figure><img src="https://lumina.shawnxie.top/backend/media/2026/02/9cd5dc59caa54e2eb425bbfed34b0674.webp" alt="" tabindex="0" decoding="async" loading="lazy"><figcaption></figcaption></figure><p>Lumina 是信息管理工作台，由 Web 应用、FastAPI 后端与浏览器扩展组成，核心动作是一键捕获网页并入库、在深度阅读页进行翻译注释评论、通过 AI 管道生成摘要大纲要点与推荐，实现从采集到洞察到治理的端到端阅读与内容管理闭环。</p><h3 id="maccy-macos-的轻量级剪贴板管理器" tabindex="-1"><a class="header-anchor" href="#maccy-macos-的轻量级剪贴板管理器"><span><a href="https://github.com/p0deje/Maccy" target="_blank" rel="noopener noreferrer">Maccy：macOS 的轻量级剪贴板管理器</a></span></a></h3><figure><img src="https://lumina.shawnxie.top/backend/media/2026/02/04b0a5f55aaf45e4a3b954fcd5fdc469.png" alt="" tabindex="0" decoding="async" loading="lazy"><figcaption></figcaption></figure><p>Maccy 是面向 macOS Sonoma 14+ 的轻量剪贴板管理器，通过快捷键调出并搜索复制历史，实现一键复制、粘贴、无格式粘贴与删除。</p><h3 id="minicpm-o-强大的开源多模态llm" tabindex="-1"><a class="header-anchor" href="#minicpm-o-强大的开源多模态llm"><span><a href="https://github.com/OpenBMB/MiniCPM-o" target="_blank" rel="noopener noreferrer">MiniCPM-o：强大的开源多模态LLM</a></span></a></h3><figure><img src="https://lumina.shawnxie.top/backend/media/2026/02/39ac0594f67843258ba45f5dae23ce2c.png" alt="" tabindex="0" decoding="async" loading="lazy"><figcaption></figcaption></figure><p>MiniCPM-o 4.5是9B开源多模态模型，可同时处理图像视频文本音频并端到端输出文本与语音，提供全双工流式交互和多语言OCR，支持多框架本地/服务器部署。</p><h3 id="picoclaw-超轻量级的个人ai助手" tabindex="-1"><a class="header-anchor" href="#picoclaw-超轻量级的个人ai助手"><span><a href="https://github.com/sipeed/picoclaw" target="_blank" rel="noopener noreferrer">PicoClaw：超轻量级的个人AI助手</a></span></a></h3><figure><img src="https://lumina.shawnxie.top/backend/media/2026/02/80b83b72aa3040058c5c89e00cb1ef8e.webp" alt="" tabindex="0" decoding="async" loading="lazy"><figcaption></figcaption></figure><p>PicoClaw是用Go从零重构的超轻量个人AI助手，架构迁移与代码优化由AI代理主导生成并人工打磨，可在10美元硬件上以不足10MB内存、1秒内启动运行。</p><h2 id="网站推荐" tabindex="-1"><a class="header-anchor" href="#网站推荐"><span>网站推荐</span></a></h2><h3 id="swe-rebench排行榜" tabindex="-1"><a class="header-anchor" href="#swe-rebench排行榜"><span><a href="https://swe-rebench.com/" target="_blank" rel="noopener noreferrer">SWE-rebench排行榜</a></span></a></h3><figure><img src="https://lumina.shawnxie.top/backend/media/2026/02/6a0fded2dc59429b8c9d5fd175c00c49.png" alt="" tabindex="0" decoding="async" loading="lazy"><figcaption></figcaption></figure><p>SWE-rebench是面向软件工程LLM的持续更新去污染基准与排行榜，按Resolved Rate、Pass@5、单题成本与token等指标评估模型，数据取自43个仓库48题并可调时间窗。</p><h2 id="资源推荐" tabindex="-1"><a class="header-anchor" href="#资源推荐"><span>资源推荐</span></a></h2><h3 id="程序员的认知心得" tabindex="-1"><a class="header-anchor" href="#程序员的认知心得"><span><a href="https://renzhi.shaogefenhao.com/#_%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2" target="_blank" rel="noopener noreferrer">程序员的认知心得</a></span></a></h3><figure><img src="http://lumina.shawnxie.top/backend/media/2026/02/877a285bd5a0496f87d22ec9113a400b.png" alt="" tabindex="0" decoding="async" loading="lazy"><figcaption></figcaption></figure><p>作者做程序员近十年，将散落的思考整理成电子书《认知心得》，强调软件工程问题的解决依赖知识经验与工作策略来强化晶体智力而非仅靠反应速度，并提醒认知必须落地实践以避免坐而论道，书中给出信息判断原则、逻辑与工程结合、模型与架构理解及团队类比分布式系统的思路。</p><h3 id="可视化神经网络学习网站" tabindex="-1"><a class="header-anchor" href="#可视化神经网络学习网站"><span><a href="https://visualrambling.space/neural-network/" target="_blank" rel="noopener noreferrer">可视化神经网络学习网站</a></span></a></h3><figure><img src="http://lumina.shawnxie.top/backend/media/2026/02/232c3b1d7955451aade7220741dda8e0.png" alt="" tabindex="0" decoding="async" loading="lazy"><figcaption></figcaption></figure><p>以互动可视化方式讲解神经网络基础，面向初学者。</p>',96)])])}const o=e(r,[["render",c]]),s=JSON.parse('{"path":"/content/2026/83.html","title":"肖恩技术周刊（第 83 期）：金句达人","lang":"zh-CN","frontmatter":{"date":"2026-02-16T00:00:00.000Z","description":"肖恩技术周刊（第 83 期）：金句达人 对周内阅读的技术内容精品（个人向）进行总结。觉得不错可点击上方订阅，第一时间获取更新通知。 蛇年最后一周，时间主要用在年终总结撰写和 Lumina 工具打磨上了，周刊开题就稍微水水吧，哈哈。 蛇年（2025）总结：决定，回顾了一年的心路历程和创作记录。没啥高光时刻，但至少保持在正道上，心里踏实不少。 Lumina...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"肖恩技术周刊（第 83 期）：金句达人\\",\\"image\\":[\\"https://cdn.jsdelivr.net/gh/shawnxie94/images/images/20260215221619389.png\\",\\"https://lumina.shawnxie.top/backend/media/2026/02/f504030f15454a4abc9053badd6dc993.png\\",\\"https://lumina.shawnxie.top/backend/media/2026/02/e436400805534eceacad68f6c4cd9405.png\\",\\"https://lumina.shawnxie.top/backend/media/2026/02/ad2593521aaf4310b7155789e4cb0430.png\\",\\"http://lumina.shawnxie.top/backend/media/2026/02/357707cb9745409a9870d5a81f2d6be4.png\\",\\"https://lumina.shawnxie.top/backend/media/2026/02/0c26b7894a3e44cb8390a6de287b6023.png\\",\\"https://lumina.shawnxie.top/backend/media/2026/02/87ec7e10cacc490dae5b69046497393e.jpg\\",\\"http://lumina.shawnxie.top/backend/media/2026/02/7933e5cfe54546959c7820efb04be492.jpg\\",\\"https://lumina.shawnxie.top/backend/media/2026/02/b4187653a3eb482ea3e8db0d7e1ec344.webp\\",\\"https://lumina.shawnxie.top/backend/media/2026/02/823d067aa312454686741451af34f4d8.webp\\",\\"https://lumina.shawnxie.top/backend/media/2026/02/bd1461b683e142c2826c29ef9a2f865d.png\\",\\"https://lumina.shawnxie.top/backend/media/2026/02/7c15b0f5aef44741a91e55b22ccd743d.jpg\\",\\"https://lumina.shawnxie.top/backend/media/2026/02/09c416a07d704b95885f2899bfad669e.png\\",\\"https://lumina.shawnxie.top/backend/media/2026/02/6bc0f80b22f74c7aa45a90cc46c621da.png\\",\\"https://lumina.shawnxie.top/backend/media/2026/02/378b17470ff842eebe3a52666b9887c1.png\\",\\"https://lumina.shawnxie.top/backend/media/2026/02/e601f113e0554115857b40e4aeccf487.webp\\",\\"http://lumina.shawnxie.top/backend/media/2026/02/5f59b550a04a4b239f552496894c149e.png\\",\\"https://lumina.shawnxie.top/backend/media/2026/02/4b43ff3e3c1b4196a77e71229f60d458.jpg\\",\\"http://lumina.shawnxie.top/backend/media/2026/02/74163cc9f26441ddbc92d157a9f8a7a6.jpg\\",\\"https://lumina.shawnxie.top/backend/media/2026/02/ddbf43713b7c451cbb3d0ec366ab0796.webp\\",\\"https://lumina.shawnxie.top/backend/media/2026/02/cb92a733b519449ba74a1fcfb5482a76.webp\\",\\"https://lumina.shawnxie.top/backend/media/2026/02/9cd5dc59caa54e2eb425bbfed34b0674.webp\\",\\"https://lumina.shawnxie.top/backend/media/2026/02/04b0a5f55aaf45e4a3b954fcd5fdc469.png\\",\\"https://lumina.shawnxie.top/backend/media/2026/02/39ac0594f67843258ba45f5dae23ce2c.png\\",\\"https://lumina.shawnxie.top/backend/media/2026/02/80b83b72aa3040058c5c89e00cb1ef8e.webp\\",\\"https://lumina.shawnxie.top/backend/media/2026/02/6a0fded2dc59429b8c9d5fd175c00c49.png\\",\\"http://lumina.shawnxie.top/backend/media/2026/02/877a285bd5a0496f87d22ec9113a400b.png\\",\\"http://lumina.shawnxie.top/backend/media/2026/02/232c3b1d7955451aade7220741dda8e0.png\\"],\\"datePublished\\":\\"2026-02-16T00:00:00.000Z\\",\\"dateModified\\":\\"2026-02-22T01:37:42.000Z\\",\\"author\\":[]}"],["meta",{"property":"og:url","content":"https://weekly.shawnxie.top/content/2026/83.html"}],["meta",{"property":"og:site_name","content":"肖恩技术周刊"}],["meta",{"property":"og:title","content":"肖恩技术周刊（第 83 期）：金句达人"}],["meta",{"property":"og:description","content":"肖恩技术周刊（第 83 期）：金句达人 对周内阅读的技术内容精品（个人向）进行总结。觉得不错可点击上方订阅，第一时间获取更新通知。 蛇年最后一周，时间主要用在年终总结撰写和 Lumina 工具打磨上了，周刊开题就稍微水水吧，哈哈。 蛇年（2025）总结：决定，回顾了一年的心路历程和创作记录。没啥高光时刻，但至少保持在正道上，心里踏实不少。 Lumina..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://cdn.jsdelivr.net/gh/shawnxie94/images/images/20260215221619389.png"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2026-02-22T01:37:42.000Z"}],["meta",{"property":"article:published_time","content":"2026-02-16T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2026-02-22T01:37:42.000Z"}]]},"git":{"createdTime":1771165079000,"updatedTime":1771724262000,"contributors":[{"name":"Shawn Xie","username":"","email":"xiexiao064@gmail.com","commits":3}]},"readingTime":{"minutes":12.74,"words":3823},"filePathRelative":"content/2026/83.md","autoDesc":true}');export{o as comp,s as data};
